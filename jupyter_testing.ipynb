{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLAN\n",
    "1. Load up to Jun 2022 into BigQuery\n",
    "2. Create github action to run BQ insert script nightly\n",
    "3. Set grouped database table (history_df) in BigQuery to refresh nightly after insert\n",
    "4. Make script to pull data history_df from BigQuery data\n",
    "\n",
    "8. For streamlit app append [history_df, current_df, future_df] to make the combo_df\n",
    "    - put history_df into cache using st.experimental_memo so its only called once each time app is opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize python libs & SQL creads\n",
    "from datetime import datetime, timedelta, date\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import streamlit as st\n",
    "import pull_nrg_data\n",
    "import json\n",
    "import http.client\n",
    "import certifi\n",
    "import ssl\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_nrg_data.release_token(accessToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token released\n"
     ]
    }
   ],
   "source": [
    "# Release token\n",
    "import certifi\n",
    "import ssl\n",
    "import http.client\n",
    "server = 'api.nrgstream.com'\n",
    "\n",
    "def release_token(accessToken):\n",
    "    path = '/api/ReleaseToken'\n",
    "    headers = {'Authorization': f'Bearer {accessToken}'}\n",
    "    context = ssl.create_default_context(cafile=certifi.where())\n",
    "    conn = http.client.HTTPSConnection(server,context=context)\n",
    "    conn.request('DELETE', path, None, headers)\n",
    "    res = conn.getresponse()\n",
    "    print('token released')\n",
    "\n",
    "accessToken = 'GI3R5KS9k5PMXiD0s-iE69JDcH1T98THkIiTR3LXEjwvzGF86jaN_lZ8tL08_FsdM4ZpGYjFtRhnyvxvJoQMhkNiwRI6ybVAy22QTDhvKNGN2V0STLG2mhWiiAcZJnIVUAbbpgchsM-medLxM36QM8-5SwTOR1TwHNqKG24uWm5RDN8e2IhA1HrZ1fNGEEqCIl7-kMrw9idj5xyA9mqqXhGuK6IV9h27LTA7du08WPXOMkHqiM8Tna4Bs8bl8SALfeXdx-eA3EdRSpExjq4gShpyfXZREsQzSW5n86vMifcmqipOsesISLGRd_rYDbcmsKgoljBkATT8rORLbSplchbc9C0'\n",
    "release_token(accessToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining daily to hourly data\n",
    "import pandas as pd\n",
    "\n",
    "intraday = pd.DataFrame(index=pd.date_range('2016-01-01', '2016-01-07', freq='H'),data=[i for i in range(145)], columns=['hourly'])\n",
    "daily = pd.DataFrame(index=pd.date_range('2016-01-01', '2016-01-07', freq='D'), data=[i for i in range(7)], columns=['daily'])\n",
    "df = intraday.join(daily).fillna(method='ffill')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b2c7660418be0c1c726d92d797a7ce8f65e49b2683610c7a567c05150d58fed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
